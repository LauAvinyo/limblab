{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LimbLab","text":"<p>Work fast, code less. Analyze your 3D limb data with ease. Aesthetic out of the box.</p> <p>Documentation: https://--</p> <p>Source Code: https://github.com/lauavinyo/limblab</p>"},{"location":"#introduction","title":"Introduction","text":"<p>Welcome to the ultimate tool for visualizing and analyzing 3D limb data, designed specifically for the scientific community working with mouse limb models (for now). Whether you're a coder or a non-coder, our pipeline offers a range of features to make your research more efficient and effective.</p> <ul> <li> <p>Accelerate Your Workflow: Say goodbye to the time-consuming task of coding from scratch or reinventing the wheel. Our pipeline allows you to work faster and focus on your research instead of getting bogged down by technical details.</p> </li> <li> <p>Limb-Specific Tools: Our pipeline is uniquely tailored for mouse limb data, providing specialized tools that are designed to meet the precise needs of your research such as 3D limb stagin and aligment to a 4D reference limb. </p> </li> <li> <p>Aesthetic Out-of-the-Box: Enjoy visually appealing outputs right from the start. Our pipeline produces high-quality, aesthetically pleasing visualizations without the need for additional customization. Present your data with confidence, knowing that it looks as good as it performs.</p> </li> <li> <p>Customizability: Built on top of Vedo, our pipeline offers extensive customizability. Whether you need to tweak a visualization or add new functionalities, you have the flexibility to build and adapt the tool to suit your specific research needs.</p> </li> <li> <p>Trusted by the Lab: Our pipeline is not just a theoretical tool; it's in active use by our research team. This means it has been tested, trusted, and proven effective in real-world scenarios, ensuring reliability and robustness for your projects.</p> </li> </ul> <p>Join the growing community of scientists who are leveraging this powerful tool to enhance their research. Our pipeline is designed to bridge the gap between complex data and meaningful insights, making it an indispensable asset for anyone working with 3D limb data.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install limblab\n</code></pre>"},{"location":"#liscence","title":"Liscence","text":""},{"location":"alternatives/","title":"Alternative and inspiration","text":"<p>For 3D data analysis, several established tools are available. Fiji and Napari are prominent options known for their robust capabilities in general 3D image analysis. These platforms excel in handling diverse image processing tasks but do not specifically cater to the specialized requirements of limb development data analysis.</p> <p>Paraview and Imaris offer advanced visualization and analytical features, providing powerful tools for complex data sets. However, these tools lack the specialized functionalities required for detailed analysis of limb gene expression studies. They do not include features tailored to the unique needs of limb development research, such as custom visualization or specific gene expression metrics.</p>"},{"location":"cli/","title":"<code>limb</code>","text":"<p>Usage:</p> <pre><code>$ limb [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>align</code></li> <li><code>clean-volume</code></li> <li><code>create-experiment</code></li> <li><code>extract-surface</code></li> <li><code>stage</code></li> <li><code>vis</code></li> </ul>"},{"location":"cli/#limb-align","title":"<code>limb align</code>","text":"<p>Usage:</p> <pre><code>$ limb align [OPTIONS] EXPERIMENT_FOLDER_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>EXPERIMENT_FOLDER_PATH</code>: Path to the experiment folder  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--morph / --no-morph</code>: Automatically pick the isovalue for the surface  [default: no-morph]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#limb-clean-volume","title":"<code>limb clean-volume</code>","text":"<p>Usage:</p> <pre><code>$ limb clean-volume [OPTIONS] EXPERIMENT_FOLDER_PATH VOLUME_PATH CHANNEL_NAME\n</code></pre> <p>Arguments:</p> <ul> <li><code>EXPERIMENT_FOLDER_PATH</code>: [required]</li> <li><code>VOLUME_PATH</code>: [required]</li> <li><code>CHANNEL_NAME</code>: [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#limb-create-experiment","title":"<code>limb create-experiment</code>","text":"<p>Usage:</p> <pre><code>$ limb create-experiment [OPTIONS] EXPERIMENT_NAME [EXPERIMENT_FOLDER_PATH]\n</code></pre> <p>Arguments:</p> <ul> <li><code>EXPERIMENT_NAME</code>: [required]</li> <li><code>[EXPERIMENT_FOLDER_PATH]</code></li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#limb-extract-surface","title":"<code>limb extract-surface</code>","text":"<p>Usage:</p> <pre><code>$ limb extract-surface [OPTIONS] EXPERIMENT_FOLDER_PATH [ISOVALUE]\n</code></pre> <p>Arguments:</p> <ul> <li><code>EXPERIMENT_FOLDER_PATH</code>: Path to the experiment folder  [required]</li> <li><code>[ISOVALUE]</code></li> </ul> <p>Options:</p> <ul> <li><code>--auto / --no-auto</code>: Automatically pick the isovalue for the surface  [default: no-auto]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#limb-stage","title":"<code>limb stage</code>","text":"<p>Usage:</p> <pre><code>$ limb stage [OPTIONS] EXPERIMENT_FOLDER_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>EXPERIMENT_FOLDER_PATH</code>: Path to the experiment folder  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#limb-vis","title":"<code>limb vis</code>","text":"<p>Usage:</p> <pre><code>$ limb vis [OPTIONS] ALGORITHM:{isosurfaces|raycast|slab|slices|probe} EXPERIMENT_FOLDER_PATH CHANNELS...\n</code></pre> <p>Arguments:</p> <ul> <li><code>ALGORITHM:{isosurfaces|raycast|slab|slices|probe}</code>: [required]</li> <li><code>EXPERIMENT_FOLDER_PATH</code>: [required]</li> <li><code>CHANNELS...</code>: [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"contribute/","title":"Contribute","text":"<p>Want to contribute? \ud83d\udc96 Text us in Github or directly at laura.avino@embl.es.</p>"},{"location":"help/","title":"Help","text":"<p>We know this package is still not in ChatGPT realms, so if you have questions, please do not hesitate to ask us in Github or directly at laura.avino@embl.es.</p>"},{"location":"releases/","title":"Release Notes","text":"<p>This will be filled up once we have a release!</p>"},{"location":"roadmap/","title":"Roadmap","text":"<p>This package works, but a lot has to be done. Starting with: </p> <ul> <li>The API for the staging system.</li> <li>Better customization of variables such as the filter cutoff, the Gaussian Blur smoothnes...</li> <li>Better styles and customization</li> </ul>"},{"location":"tutorials/hoxa11/","title":"Hoxa11 Pipeline","text":"<p>Welcome to the comprehensive guide on analyzing HCR with Hoxa11 expression using our advanced pipeline. This guide is tailored for researchers looking to delve deeper into 3D gene expression data, specifically focusing on the Hoxa11 gene in mouse limb models. By following this guide, you will gain a thorough understanding of how to set up, clean, analyze, and visualize 3D limb data effectively.</p>"},{"location":"tutorials/hoxa11/#the-goal","title":"The Goal","text":"<p>The primary objective of this guide is to analyze HCR (Hybridization Chain Reaction) with Hoxa11 expression. This is particularly interesting because the traditional 2D projection may not accurately represent the gene expression in a 3D context. Understanding the 3D spatial distribution of Hoxa11 can provide deeper insights into its role and functionality in limb development.</p>"},{"location":"tutorials/hoxa11/#the-pipeline","title":"The Pipeline","text":"<p>The raw data required for this analysis can be found in the <code>example_data/hoxa11_raw_data</code> directory. This folder contains the TIFF volumes for both Hoxa11 and DAPI channels.</p>"},{"location":"tutorials/hoxa11/#setting-up-the-experiment","title":"Setting Up the Experiment","text":"<p>Before starting the analysis, it's crucial to set up a new experiment to ensure the raw data remains unaltered. To do this, run the following command:</p> <pre><code>limb create-experiment case_studies/hoxa11_pipeline\n</code></pre> <p>This command generates a log file for the experiment and prompts the user to input details about the limb, such as whether it's a Forelimb or Hindlimb, Left or Right side, and the microscope spacing. For our example, the inputs are as follows: Left, Hindlimb, with a default spacing value of 0.65 0.65 2. </p> <p>The log file <code>pipeline.log</code> will help in tracking the experiment settings and ensuring reproducibility. Your <code>pipeline.log</code> file should now look like this:</p> <pre><code>BASE ./case_studies/hoxa11_pipeline\nSIDE L\nPOSITION H\nSPACING 0.65 0.65 2.0\n</code></pre>"},{"location":"tutorials/hoxa11/#volume-clean-up","title":"Volume Clean-Up","text":"<p>The next step is to clean up the volumes, starting with the DAPI channel. Cleaning up involves removing noise and irrelevant data to get a clear representation of the limb's structure. This process includes selecting isovalues to clip the volume.</p> <p>To clean the DAPI volume, use the following command:</p> <pre><code>limb clean-volume case_studies/hoxa11_pipeline example_data/hoxa11_raw_data/HCR11_HOXA11_l1_dapi_488_LH.tif dapi\n</code></pre> <p>A plotter will appear, prompting you to select the top and bottom isovalues. This helps in clipping the volume to eliminate noise. After smoothing, confirm that everything looks fine. Repeat the process for the Hoxa11 channel:</p> <pre><code>limb clean-volume case_studies/hoxa11_pipeline example_data/hoxa11_raw_data/HCR11_HOXA11_l1_hoxa11_647_LH.tif hoxa11\n</code></pre> <p>Note: This step is time-consuming as it involves careful selection and verification of isovalues to ensure data integrity.</p>"},{"location":"tutorials/hoxa11/#analyzing-the-limb","title":"Analyzing the Limb","text":"<p>To analyze the limb, follow these steps:</p> <ol> <li>Extract the Limb Surface</li> <li>Stage the Limb</li> <li>Align the Limb to a Reference Limb</li> </ol>"},{"location":"tutorials/hoxa11/#surface-extraction","title":"Surface Extraction","text":"<p>Surface extraction involves creating a 3D representation of the limb's surface, which is crucial for further analysis. Run the following command to start the process:</p> <pre><code>limb extract-surface case_studies/hoxa11_pipeline/\n</code></pre> <p>If you don't specify an isovalue, a plotter will prompt you to select the appropriate isovalue manually. This ensures that the surface extraction is based on the correct data points.</p>"},{"location":"tutorials/hoxa11/#stage-the-limb","title":"Stage the Limb","text":"<p>Staging the limb involves determining its developmental stage based on its morphology. To stage the limb, use the command:</p> <pre><code>limb stage case_studies/hoxa11_pipeline/\n</code></pre> <p>A plotter will appear where you can click on the limb's contour. After clicking 's', the limb's stage will be determined. This process involves selecting key morphological points which are then used to calculate the stage of the limb.</p> <p>Depending on whether you're using a local or server version, this will generate:</p> <ol> <li>A file with the measured points</li> <li>A file with the fit line</li> <li>An image with the results (local version)</li> </ol>"},{"location":"tutorials/hoxa11/#align-the-limb","title":"Align the Limb","text":"<p>Alignment ensures that the limb's data is comparable to a reference model, which is essential for accurate analysis. You have two options for alignment:</p> <ol> <li>Linear Transformation (rotation and scaling)</li> <li>Non-Linear Transformation (morphing)</li> </ol> <p>For this example, we will use a linear transformation. This involves rotating and scaling the limb to match the reference model, making it easier to compare and analyze the data.</p>"},{"location":"tutorials/hoxa11/#visualizing-the-limb-expression","title":"Visualizing the Limb Expression","text":"<p>Visualization helps in interpreting the data by providing a clear, graphical representation of the gene expression.</p>"},{"location":"tutorials/hoxa11/#visualize-the-isosurfaces","title":"Visualize the Isosurfaces","text":"<p>Isosurfaces represent surfaces of constant value within the volume data. To visualize the isosurfaces, run:</p> <pre><code>limb vis isosurfaces case_studies/hoxa11_pipeline HOXA11\n</code></pre> <p>If the isosurfaces have not been computed yet, a plotter will prompt you to select the top and bottom isovalues, enabling you to customize the visualization according to your needs.</p>"},{"location":"tutorials/hoxa11/#visualize-the-slab","title":"Visualize the Slab","text":"<p>To visualize the 2D projection using the dynamic slab, use:</p> <pre><code>limb vis slab case_studies/hoxa11_pipeline HOXA11\n</code></pre> <p>This command provides a dynamic view of the data, allowing you to observe the gene expression in a 2D context while retaining the depth information from the 3D data.</p>"},{"location":"tutorials/sox9_bmp2/","title":"Sox9 and BMP2 Pipeline","text":"<p>Here you can find a detailed exploration of HCR data showcasing Sox9 and BMP2 expression using our pipeline. We will follow the same steps as in the other tutorial now with a specific focus on examining the gene expression overlap between Sox9 and BMP2 genes.</p>"},{"location":"tutorials/sox9_bmp2/#objective","title":"Objective","text":"<p>Our aim is to investigate the HCR (Hybridization Chain Reaction) data to observe the spatial distribution of Sox9 and BMP2 expression. Analyzing these genes in three dimensions can reveal their interaction and roles in limb development more accurately than traditional 2D projections (2D sections may arguable be the best technique tho).</p>"},{"location":"tutorials/sox9_bmp2/#pipeline-overview","title":"Pipeline Overview","text":"<p>The initial data required for this study is located in the <code>example_data/sox9_bmp2_raw_data</code> directory. This directory contains TIFF volumes for both Sox9 and BMP2 channels.</p>"},{"location":"tutorials/sox9_bmp2/#initial-setup","title":"Initial Setup","text":"<p>To maintain the integrity of your raw data, start by creating a new experiment folder separated from it. Execute the following command:</p> <pre><code>limb create-experiment case_studies/sox9_bmp2_pipeline\n</code></pre> <p>You'll be prompted to enter details about the limb, such as whether it's a Forelimb or Hindlimb, Left or Right side, and the microscope's spacing parameters. For this demonstration, we use: Left, Forelimb, with a default spacing value of 0.65 0.65 2.</p> <p>Your <code>pipeline.log</code> file should now resemble:</p> <pre><code>BASE ./case_studies/sox9_bmp2_pipeline\nSIDE L\nPOSITION F\nSPACING 0.65 0.65 2.0\n</code></pre>"},{"location":"tutorials/sox9_bmp2/#cleaning-the-volumes","title":"Cleaning the Volumes","text":"<p>The next step involves preparing the volumes, beginning with the DAPI channel. Cleaning involves removing noise to get a clear structure of the limb. Execute the command:</p> <pre><code>limb clean-volume case_studies/sox9_bmp2_pipeline example_data/sox9_bmp2_raw_data/HCR20_BMP2_l1_dapi_405_LF.tif dapi\n</code></pre> <p>A plotter will prompt you to select isovalues to clip the volume, eliminating noise. Confirm the smoothness of the volume afterward. Repeat the procedure for the Sox9 and BMP2 channels:</p> <pre><code>limb clean-volume case_studies/sox9_bmp2_pipeline example_data/sox9_bmp2_raw_data/HCR20_BMP2_l1_sox9_594_LF.tif sox9\nlimb clean-volume case_studies/sox9_bmp2_pipeline example_data/sox9_bmp2_raw_data/HCR20_BMP2_l1_bmp2_647_LF.tif bmp2\n</code></pre> <p>Note: This step requires patience as careful selection of isovalues is critical.</p>"},{"location":"tutorials/sox9_bmp2/#limb-analysis","title":"Limb Analysis","text":"<p>Proceed with the following steps to analyze the limb:</p> <ol> <li>Extract the Limb Surface</li> <li>Stage the Limb</li> <li>Align the Limb with a Reference</li> </ol>"},{"location":"tutorials/sox9_bmp2/#extracting-the-surface","title":"Extracting the Surface","text":"<p>Surface extraction creates a 3D model of the limb, essential for further analysis since, trying to align volumes to references will be very computationally consuming. Initiate the process by running:</p> <p><pre><code>limb extract-surface case_studies/sox9_bmp2_pipeline/\n</code></pre> You will be able to notice that this isosurface is not very beautiful, real life experiments. We are working on a a way to clean it surface through with this pipeline. Do not hesitate to contact us about how to do this. For now, we have shared a clean version of the surface using blender. For the code to use it in you next step, please, add the next line to your pipeline.log file.  You can do it by:  <pre><code>echo 'BLENDER HCR20_BMP2_l1_dapi_405_LF_surface_blender.vtk' &gt;&gt; case_studies/sox9_bmp2_pipeline/pipeline.log\ncp example_data/sox9_bmp2_raw_data/HCR20_BMP2_l1_dapi_405_LF_surface_blender.vtk case_studies/sox9_bmp2_pipeline \n</code></pre></p>"},{"location":"tutorials/sox9_bmp2/#staging-the-limb","title":"Staging the Limb","text":"<p>Staging involves determining the developmental stage of the limb. Execute:</p> <pre><code>limb stage case_studies/sox9_bmp2_pipeline/\n</code></pre> <p>A plotter will appear where you mark the limb's contour. Click 's' to determine the stage. This process generates key files and images depending on whether you're using a local or server version.</p>"},{"location":"tutorials/sox9_bmp2/#aligning-the-limb","title":"Aligning the Limb","text":"<p>Aligning the limb ensures it matches a reference model for precise analysis. You have two methods:</p> <ol> <li>Linear Transformation (rotation and scaling)</li> <li>Non-Linear Transformation (morphing)</li> </ol> <pre><code>limb stage case_studies/sox9_bmp2_pipeline/ --morph\n</code></pre>"},{"location":"tutorials/sox9_bmp2/#visualizing-gene-expression","title":"Visualizing Gene Expression","text":"<p>Visualization helps interpret the data, providing a clear graphical representation of gene expression.</p>"},{"location":"tutorials/sox9_bmp2/#viewing-isosurfaces","title":"Viewing Isosurfaces","text":"<p>Let's visualize the isosurfaces for both genes at the same time. Visualize them by running:</p> <pre><code>limb vis isosurfaces case_studies/sox9_bmp2_pipeline SOX9 BMP2\n</code></pre> <p>If the isosurfaces are not precomputed, a plotter will help you select appropriate isovalues for visualization.</p>"},{"location":"userGuide/align/","title":"Align CLI Tool","text":"<p>This document provides detailed technical information on the <code>align</code> function, which is executed using the CLI command:</p> <pre><code>limb align &lt;folder_path&gt; [--morph]\n</code></pre> <p>TLDR;  In essence, the <code>align</code> function is designed to align a 3D surface mesh of a limb with a reference model through either rotation or morphing, depending on the presence of the <code>--morph</code> flag. If the <code>--morph</code> flag is set, the function performs a morphing alignment; otherwise, it defaults to a rotational alignment. We use this functionality to ensyre that the limb model aligns accurately with a reference model, which is essential for detailed analysis and comparison.</p>"},{"location":"userGuide/align/#detailed-workflow","title":"Detailed Workflow","text":"<p>When you invoke the <code>align</code> function, it determines the alignment method based on the <code>morph</code> parameter.</p>"},{"location":"userGuide/align/#rotation-alignment","title":"Rotation Alignment","text":"<p>For rotational alignment, the function delegates the task to <code>_rotate_limb</code>. This process begins by loading the pipeline configuration from the experiment folder and retrieving the path to the surface mesh and the stage information. If the staging algorithm has not been completed, the function will prompt you to run it first. </p> <p>Next, the function fetches the reference limb corresponding to the current stage. It then loads the source and target meshes for visualization, allowing manual alignment through interactive adjustments. This manual alignment enables you to ensure that the limb model matches the reference model as closely as possible. The function computes a transformation matrix based on your adjustments and saves this matrix to disk. It then updates the pipeline configuration with this transformation matrix and the rotation details.</p>"},{"location":"userGuide/align/#morphing-alignment","title":"Morphing Alignment","text":"<p>If the <code>--morph</code> flag is used, the function invokes <code>_morph_limb</code> instead. This process similarly starts by loading the pipeline configuration and retrieving the surface mesh and stage information. The function checks to ensure that the staging algorithm has been executed. If not, it prompts you to run it before proceeding.</p> <p>The function then retrieves the reference limb for the current stage and uses a morphing tool to calculate the transformation required to align the source mesh with the reference model. This morphing transformation adjusts the mesh to fit the reference model more accurately. Once the transformation is computed, it is saved to disk, and the pipeline configuration is updated with the new morphing information.</p>"},{"location":"userGuide/align/#example-usage","title":"Example Usage","text":"<p>To perform a rotational alignment programmatically, you can use the following code:</p> <pre><code>from pathlib import Path\n\n# Define the path to the experiment folder\nexperiment_folder_path = Path(\"/path/to/experiment\")\n\n# Execute the function to perform rotational alignment\n_rotate_limb(experiment_folder_path)\n</code></pre> <p>For morphing alignment, the code would look like this:</p> <pre><code>from pathlib import Path\n\n# Define the path to the experiment folder\nexperiment_folder_path = Path(\"/path/to/experiment\")\n\n# Execute the function to perform morphing alignment\n_morph_limb(experiment_folder_path)\n</code></pre>"},{"location":"userGuide/staging/","title":"3D Staging System","text":"<p>This document offers a thorough overview of the <code>stage</code> function, which is executed through the CLI command:</p> <pre><code>limb stage &lt;folder_path&gt;\n</code></pre> <p>Warning</p> <p>The server is still not public, so, for now, we recommend using the local exectuble found in the Gene Mapper.  Make sure to change the  enviroment variable to your executable </p>"},{"location":"userGuide/staging/#the-function-stage","title":"The Function: <code>stage</code>","text":"<p>TLDR; The <code>stage</code> function is crucial for preparing a 3D limb model for analysis by fitting a plane to the model and processing this information either through a remote server or a local executable. This process aligns and calibrates the model, making it ready for further stages of analysis or study.</p>"},{"location":"userGuide/staging/#workflow","title":"Workflow","text":"<p>When you call the <code>stage</code> function, it triggers the <code>_stage_limb</code> function, which orchestrates the staging process. Here\u2019s how it unfolds:</p> <p>Firstly, the function loads the configuration from a file named <code>pipeline.log</code>, located in the experiment folder. This file provides the path to the surface mesh that will be staged. </p> <p>The function then attempts to connect to the server. If the server connection is successful and the server responds with valid data, the function proceeds to use this server to process the staging information. In the event that the server is unreachable or fails to respond, the function defaults to using a local executable to handle the staging. If there is no executable, nor a connection with the server, the program exits.</p> <p>Once the server connection is established, or the fallback to the local executable is confirmed, the function sets up an interactive 3D visualization environment. Here, users can manually fit a plane to the limb model. Through this interactive tool, users can add points to define the plane's orientation and position. After fitting the plane, the function applies a transformation to the limb model to align it based on the defined plane.</p> <p>Following the manual alignment, the function processes the fit data. If using the server, it sends the data as a JSON payload, which the server processes and returns with the staging result. If the executable is used, the function writes the fit data to a temporary file and runs the local executable to process the data. It then retrieves the staging result from the output generated by the local executable.</p> <p>Finally, regardless of whether the server or the local executable was used, the function updates the pipeline configuration with the new staging result and saves this updated configuration back to the <code>pipeline.log</code> file.</p>"},{"location":"userGuide/staging/#example-usage","title":"Example Usage","text":"<p>To execute the staging process programmatically, you can use the following snippet:</p> <pre><code>from pathlib import Path\n\n# Define the path to the experiment folder\nexperiment_folder_path = Path(\"/path/to/experiment\")\n\n# Execute the function to perform the staging process\n_stage_limb(experiment_folder_path)\n</code></pre>"},{"location":"userGuide/style/","title":"Styles","text":"<p>TLDR; The <code>customization.py</code> file is designed to provide users with the ability to adjust the visual aspects of the application to better meet their preferences or requirements. This file contains a dictionary named <code>styles</code> as well that outlines various parameters for customizing colors, transparencies, and positions of different elements in the application.</p> <p>Warning</p> <p>This is still in development. Maybe unreliable.</p>"},{"location":"userGuide/style/#understanding-the-styles-dictionary","title":"Understanding the Styles Dictionary","text":"<p>The <code>styles</code> dictionary within the file is structured to define a range of visual attributes for different elements. Here\u2019s a detailed look at how you can utilize and modify these settings.</p> <p>Color Schemes are defined by keys <code>0</code> and <code>1</code>. These keys correspond to pairs of color values that can be used to apply a specific color theme across different components of the application. For example, key <code>0</code> is associated with a light blue color (<code>#9ce4f3</code>) and a dark blue color (<code>#128099</code>), while key <code>1</code> pairs a light pink (<code>#ec96f2</code>) with a dark purple (<code>#c90dd6</code>). You can use them for different channels for instance. </p> <p>Positions for various UI elements are specified under the <code>postions</code> key (mainly sliders). This includes the <code>number</code> and <code>values</code> coordinates, which dictate where numerical and value indicators should appear within the interface. The coordinates <code>[0.1, 0.25]</code> and <code>[0.2, 0.25]</code> are examples for positioning numerical indicators, whereas <code>[0.1, 0.1]</code> and <code>[0.2, 0.1]</code> are used for value indicators.</p> <p>Limb Appearance settings are found under the <code>limb</code> key. This section allows you to adjust the color and transparency of limb models within the application. The <code>alpha</code> value of <code>0.1</code> ensures that the limb appears very transparent, while the color <code>#FF7F11</code> gives it an orange tint.</p> <p>Reference Appearance is defined by the <code>reference</code> key, where <code>alpha</code> is set to <code>1</code>, indicating full opacity, and <code>color</code> is set to <code>1</code>, which typically represents white in RGB color space.</p> <p>Isosurfaces customization is handled under the <code>isosurfaces</code> key. Here, the transparency levels for isosurfaces are specified. The <code>alpha</code> value of <code>0.3</code> adjusts the general transparency of isosurfaces, while <code>alpha-unique</code> at <code>0.8</code> applies a higher transparency level for unique or highlighted isosurfaces.</p> <p>User Interface (UI) Colors are controlled by the <code>ui</code> key. The <code>primary</code> color (<code>#0d1b2a</code>) sets the main color scheme of the UI, while the <code>secondary</code> color (<code>#fb8f00</code>) is used for accent elements, providing a vibrant orange contrast to the primary dark blue.</p>"},{"location":"userGuide/style/#applying-customizations","title":"Applying Customizations","text":"<p>To change the appearance of different elements, you simply need to update the relevant values within this dictionary. For example, if you want to alter the limb color, you would modify the <code>color</code> attribute in the <code>limb</code> section. Similarly, adjusting the UI color scheme involves updating the <code>primary</code> and <code>secondary</code> colors under the <code>ui</code> key. </p>"},{"location":"userGuide/surface/","title":"Surface Extraction","text":""},{"location":"userGuide/surface/#extract-surface-cli-tool","title":"Extract Surface CLI Tool","text":"<p>This document provides detailed technical information on the <code>extract_surface</code> function. The function is invoked by the CLI command:</p> <pre><code>limb extract-surface &lt;folder_path&gt; [isovalue] [--auto]\n</code></pre>"},{"location":"userGuide/surface/#the-function-extract_surface","title":"The function: <code>extract_surface</code>","text":"<p>TLDR; The <code>extract_surface</code> function extracts a 3D surface from a volume dataset based on an isovalue. You can specify the isovalue manually or let the function automatically determine it based on the volume data. The function processes the volume data, extracts the surface, decimates it to reduce complexity, and saves the result. This function is vital for generating surface representations of volumetric data.</p>"},{"location":"userGuide/surface/#parameters","title":"Parameters","text":"<ul> <li>experiment_folder_path (Path): The path to the directory where the experiment data and configurations are stored.</li> <li>isovalue (Optional[int]): A specific isovalue to use for extracting the surface. If not provided, the function will either compute it automatically or prompt the user for selection.</li> <li>auto (bool): If set to <code>True</code>, the function will automatically determine the isovalue from the volume data. If <code>False</code> and no isovalue is provided, the user will be prompted to select one interactively.</li> </ul>"},{"location":"userGuide/surface/#workflow","title":"Workflow","text":"<p>The function starts by loading the pipeline configuration from the <code>experiment_folder_path</code>. It checks for the existence of the DAPI volume, which is required for processing. If the volume is missing, an error message is displayed, and the function terminates. You will have to go back and clean it. </p> <p>The function then locates the DAPI volume file and loads it into memory. If an isovalue is provided as an argument, it is used directly. If the <code>auto</code> flag is set and no isovalue is provided, the function calculates an automatic isovalue by analyzing the volume's histogram. The histogram's mean value is used as the isovalue for surface extraction. If neither an isovalue nor the <code>auto</code> flag is provided, an interactive tool (<code>IsosurfaceBrowser</code>) is launched to allow the user to select an isovalue manually. The selected value is displayed for confirmation.</p> <p>Once the isovalue is determined, the function proceeds to compute the isosurface using the specified value. The surface is then processed to extract the largest connected region and decimated to reduce the number of points and improve efficientcy down the line.</p> <p>The decimated surface is saved to a file with the suffix <code>_surface.vtk</code>, and the path to this file is updated in the pipeline configuration. The updated pipeline configuration is saved back to the <code>pipeline.log</code> file in the experiment folder.</p>"},{"location":"userGuide/surface/#example-usage","title":"Example Usage","text":"<p>You could use the <code>extract_surface</code> function programmatically as follows:</p> <pre><code>from pathlib import Path\n\n# Define paths and options\nexperiment_folder_path = Path(\"/path/to/experiment\")\nisovalue = 150  # Optional: specify an isovalue or leave as None\nauto = True  # Set to True for automatic isovalue detection\n\n# Extract the surface\n_extract_surface(experiment_folder_path, isovalue, auto)\n</code></pre>"},{"location":"userGuide/volume/","title":"Clean Volume CLI Tool","text":"<p>This document provides detailed technical information on the <code>clean_volume</code> function. The function called by the CLI command: <pre><code>limb clean-volume &lt;folder_path&gt; &lt;volume_path&gt; &lt;channel_name&gt;\n</code></pre></p>"},{"location":"userGuide/volume/#the-function-clean_volume","title":"The function: <code>clean_volume</code>","text":"<p>TLDR; The <code>clean_volume</code> function processes raw volume data by performing a series of steps including loading pipeline configurations, applying filters, resizing, and saving the cleaned volume. This function is essential for preparing volume data for subsequent steps. You must use it. Also, depending on your raw data format, you may reduce a lot the size of the file. </p>"},{"location":"userGuide/volume/#parameters","title":"Parameters","text":"<ul> <li>experiment_folder_path (Path): The directory path where the experiment data and configurations are stored.</li> <li>volume_path (Path): The path to the raw volume file that needs to be processed.</li> <li>channel_name (str): The name of the channel to be processed, typically representing a specific staining or imaging channel.</li> </ul>"},{"location":"userGuide/volume/#workflow","title":"Workflow","text":"<p>First of it converts the channel name to uppercase for consistency (as you may have seen in the pipeline.log files). Then, it reads the pipeline configuration from the <code>experiment_folder_path</code>. We need the parameters <code>SIDE</code> (indicating the anatomical side of the limb) and <code>SPACING</code> (voxel spacing).  We set the constants: the Gaussian smoothing (<code>SIGMA</code>) to (6, 6, 6), frequency cutoff (<code>CUTOFF</code>) to 0.05, and volume size to (512, 512, 296). For now, the values are set, but it's plan passed as parameters in future releases. </p> <p>The raw volume file is loaded into memory for processing, and the voxel spacing is applied to ensure accurate dimensional representation. Then and interactive tool popups to allow users to select bottom and top isovalues for thresholding, which determine the intensity range to be preserved in the volume. The volume is then thresholded based on the selected isovalues, replacing out-of-range values and resizing the volume to the specified dimensions. If the volume corresponds to the left side (<code>SIDE == \"L\"</code>), it mirrors the volume for symmetry. Gaussian smoothing and frequency pass filtering are applied to reduce noise and remove high-frequency artifacts.</p> <p>Finally, the processed volume is written to disk, and the pipeline configuration is updated with metadata, including the processed volume path and selected isovalues. The updated pipeline configuration is saved back to the <code>experiment_folder_path</code>.</p>"},{"location":"userGuide/volume/#example-usage","title":"Example Usage","text":"<p>You could use the helper function on its own: </p> <pre><code>from pathlib import Path\n\n# Define paths and channel\nexperiment_folder_path = Path(\"/path/to/experiment\")\nvolume_path = Path(\"/path/to/raw_volume.tif\")\nchannel_name = \"dapi\"\n\n# Clean the volume\n_clean_volume(experiment_folder_path, volume_path, channel_name)\n</code></pre>"},{"location":"userGuide/vis/isosurfaces/","title":"Isosurface Visualitzation","text":""},{"location":"userGuide/vis/vis/","title":"Visualitzation","text":"<p>Certainly! Below is the revised text with \"limb\" in place of \"your_script.py\":</p>"},{"location":"userGuide/vis/vis/#command-documentation-vis","title":"Command Documentation: <code>vis</code>","text":"<p>The <code>vis</code> command is the tool for visualizing 3D limbs, offering a range of algorithms tailored to various analysis needs. This command plays a crucial role in transforming raw data into meaningful visual representations.</p> <p>Tip</p> <p>We are developing more visualitzation algorithms! Keep posted.</p> <p>To utilize the <code>vis</code> command effectively, specify the desired visualization algorithm, provide the path to your experiment data, and list the channels you want to visualize. Each algorithm is optimized for different types of visualizations. Currently you can visualize isoseufaces, slabs, raycast, probe and slices of your volumes.</p>"},{"location":"userGuide/vis/vis/#visualization-algorithms","title":"Visualization Algorithms","text":""},{"location":"userGuide/vis/vis/#isosurface-visualization","title":"Isosurface Visualization","text":"<p>The isosurface algorithm is used to render three-dimensional surfaces within a volume of data, highlighting specific features or regions of interest. Depending on your needs, you can choose to visualize one or two channels, just by setting the channel(s). If the number of channels provided is not as expected (one or two), a <code>NotImplementedError</code> will be raised to ensure valid configurations.</p> <pre><code>limb vis isosurface /data/experiment/ channel_1 (channel_2)\n</code></pre>"},{"location":"userGuide/vis/vis/#raycast-visualization","title":"Raycast Visualization","text":"<p>The raycasting algorithm generates a two-dimensional projection from a three-dimensional dataset by projecting data along a specified direction. This technique is excellent for visualizing internal structures and data distribution within the volume. Since raycasting supports only one channel at a time, a warning will be issued if multiple channels are specified, and the first channel in the list will be used for the projection. This method is useful for creating projections that reveal internal features or patterns within a 3D model.</p> <pre><code>limb vis raycast /data/experiment/ channel_1\n</code></pre>"},{"location":"userGuide/vis/vis/#slices-visualization","title":"Slices Visualization","text":"<p>The slices algorithm creates two-dimensional cross-sections from a three-dimensional dataset, producing multiple 2D slices at various depths. This allows users to examine different planes within the data volume, providing a detailed view of the structural organization across various sections. For example, slices can be used to investigate internal layers or planes within a 3D model.</p> <pre><code>limb vis slices /data/experiment/ channel_1\n</code></pre>"},{"location":"userGuide/vis/vis/#probe-visualization","title":"Probe Visualization","text":"<p>The probe algorithm enables interactive exploration of specific points or regions within the 3D data. This feature is valuable for extracting detailed information from selected areas of interest. By focusing on one channel, the <code>probe</code> function allows for detailed examination of points or regions, which is essential for analyzing gene expression levels or other features at specific locations within the tissue.</p> <pre><code>limb vis probe /data/experiment/ channel_1\n</code></pre>"},{"location":"userGuide/vis/vis/#slab-visualization","title":"Slab Visualization","text":"<p>The slab algorithm visualizes a subset of the data within a defined slab or section of the 3D volume. This method helps users focus on specific layers or regions, providing a clearer view of particular sections. The <code>slab</code> function, which operates on one channel, enables users to create a focused view within a defined section of the dataset, highlighting features within a particular layer of a 3D structure.</p> <pre><code>limb vis slab /data/experiment/ channel_1\n</code></pre>"}]}